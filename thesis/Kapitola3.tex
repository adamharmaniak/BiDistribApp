\chapter{Združené rozdelenie pravdepodobnosti}\label{sec:joint_dist}

V predchádzajúcich kapitolách sme sa zaoberali modelovaním rozdelenia pravdepodobnosti jednotlivých náhodných premenných alebo cieľových premenných v kontexte regresie a klasifikácie. V oboch týchto prístupoch sme vychádzali prevažne z predpokladu, že modelujeme samostatnú premennú alebo závislosť jednej výstupnej premennej na vstupe. V praxi však častokrát pracujeme s viacerými náhodnými premennými súčasne, ktorých správanie môže byť navzájom ovplyvňované. Ich spoločné správanie popisuje tzv. \textit{združené rozdelenie pravdepodobnosti}.

Ak premenné modelujeme ako komponenty náhodného vektora $\vec{X} = (X_1, X_2)$, potom znalosť ich združeného rozdelenia nám umožňuje odvodiť ďalšie dôležité vlastnosti systému – napríklad ako vyzerajú podmienené rozdelenia, marginálne rozdelenia alebo podmienená stredná hodnota jednej premennej vzhľadom k druhej a naopak. Tieto pojmy sú kľúčové nielen pre štatistické modelovanie ako také, ale aj pre praktické aplikácie ako sú predikcie, rozhodovania sa založené na týchto predikciách alebo celková analýza závislostí.

Presné vyjadrenie alebo odhad združeného rozdelenia je však zložitý, čo je podnecované vyšším počtom premenných. S rastúcim rozmerom vektora náhodných premenných rastie aj počet parametrov a miera závislosti, ktorú je potrebné zohľadniť. Preto sa častokrát používajú zjednodušujúce predpoklady, napríklad o nezávislosti alebo naopak špecifickej štruktúre závislosti medzi premennými. My sa však budeme zaoberať modelovaním združeného rozdelenia práve dvoch náhodných premenných.

V tejto kapitole sa zameriame na:
\begin{itemize}
  \item základy modelovania združeného rozdelenia, vrátane podmienených a marginálnych funkcií,
  \item rozklad združeného rozdelenia na marginálne rozdelenia a kopulovú funkciu,
  \item praktické aspekty odhadu združeného rozdelenia na základe dostupných údajov.
\end{itemize}

Konkrétne budeme v tejto kapitole pracovať so združenými rozdeleniami náhodných premenných rovnakého typu – teda buď čisto spojitými, alebo čisto diskrétnymi. Budeme rozoberať všeobecné princípy modelovania, analýzy a odhady takýchto rozdelení. Praktické príklady budú vychádzať z regresných a klasifikačných kontextov, kde sa využívajú znalosti o marginálnych a podmienených rozdeleniach. Pre ilustráciu štruktúry dát a závislostí medzi premennými využijeme nástroje popisnej štatistiky a vizualizačné techniky, ktoré sú súčasťou výstupov mnou implementovanej interaktívnej aplikácie. Táto aplikácia predstavuje aplikačnú časť tejto bakalárskej práce a poskytuje praktické vizualizačné a analytické nástroje na skúmanie združených rozdelení pravdepodobnosti, ktoré sú využité aj pri prezentácii výsledkov v tejto kapitole. Modelovanie zmesi spojitých a diskrétnych náhodných premenných, ako špecifický prípad heterogénnych štruktúr, bude predmetom samostatnej kapitoly, keďže ide o hlavnú problematiku, na ktorú sa v tejto práci chceme zamerať.


\section{Základy modelovania}\label{sec:joint_zaklady_modelovania}

\subsection{Funkčná reprezentácia}\label{subsec:joint_representation}

Podobne ako to bolo v jednorozmernom prípade, aj viacrozmerné združené rozdelenie možno reprezentovať rôznymi funkciami. My sa v tejto práci budeme zaoberať iba dvojrozmerným prípadom. Dve náhodné premenné $X_1$ a $X_2$ teda môžeme opísať buď pomocou ich spoločnej distribučnej funkcie (angl. joint cumulative distribution function – CDF), alebo pomocou ďalších vhodných nástrojov v závislosti od typu premenných.

\subsubsection{Kumulatívna distribučná funkcia (CDF)}\label{subsec:joint_cdf}

Spoločná distribučná funkcia $F(x_1, x_2)$ dvoch náhodných premenných $X_1$ a $X_2$ vyjadruje pravdepodobnosť, že obe premenné nadobudnú súčasne hodnoty najviac $x_1$ a $x_2$:

\begin{equation}
F(x_1, x_2) = \mathrm{Pr}(X_1 \leq x_1,\ X_2 \leq x_2),
\end{equation}

pričom vo vzťahu k združenej hustote týchto premenných platia nasledujúce vzťahy:

\begin{equation}
F(x_1, x_2) = \int_{-\infty}^{x_1} \int_{-\infty}^{x_2} f(y_1, y_2) \, dy_1 dy_2
\end{equation}

\begin{equation}
f(x) = \left. \frac{\partial^2 F(y_1, y_2)}{\partial y_1 \partial y_2} \right|_{y = x}
\end{equation}

\subsubsection{Združená hustota pravdepodobnosti (PDF)}\label{subsec:joint_pdf}

Ak sú premenné spojité, spoločné rozdelenie opisujeme prostredníctvom \textit{združenej hustoty pravdepodobnosti} (angl. joint probability density function – PDF) $f(x_1, x_2)$, ktorá udáva pravdepodobnostnú hustotu výskytu dvojice hodnôt v danej oblasti roviny $\mathbb{R}^2$.

V prípade diskrétnych premenných sa namiesto hustoty používa \textit{združená pravdepodobnostná funkcia} (angl. joint probability mass function – PMF), ktorá každému páru hodnôt $(x_1, x_2)$ priraďuje konkrétnu pravdepodobnosť výskytu: 

\begin{equation}
p(x_1, x_2) = \mathrm{Pr}(X_1 = x_1,\, X_2 = x_2)
\end{equation}

Táto pravdepodobnosť je daná explicitne pre jednotlivé kombinácie hodnôt, pričom platí:

\begin{equation}
\sum_{x_1} \sum_{x_2} p(x_1, x_2) = 1
\end{equation}

Bez ohľadu na typ premenných platí, že združené rozdelenie poskytuje kompletný popis ich spoločného správania a tvorí základ pre odvodenie marginálnych a podmienených rozdelení, ako aj závislostí medzi premennými.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{SK_verzia_praca/figures/pravdeb_funk_ostrov_druhy_3D.png}
    \caption{Združená pravdepodobnostná funkcia (PMF) medzi premennými \textit{Ostrov ako miesto výskytu} a \textit{Druh} tučniakov.}
    \label{fig:miesto_druh_joint_density}
\end{figure}

Zatiaľ čo v jednorozmernom spojitom prípade nás zaujímala pravdepodobnosť výskytu náhodnej premennej v určitej oblasti na reálnej osi, v prípade dvoch spojitých premenných nás už zaujíma pravdepodobnosť, že realizácie oboch premenných spadnú do danej oblasti v rovine $\mathbb{R}^2$.

Ak $R_1 = [x_1, x_1 + dx_1]$ a $R_2 = [x_2, x_2 + dx_2]$ sú malé intervaly okolo bodu $(x_1, x_2)$, potom pravdepodobnosť, že náhodný vektor $(X_1, X_2)$ spadne do oblasti $R_1 \times R_2$, je približne:

\begin{equation}
\mathrm{Pr}(x_1 \leq X_1 \leq x_1 + dx_1,\ x_2 \leq X_2 \leq x_2 + dx_2) \approx f(x_1, x_2) \, dx_1 \, dx_2
\end{equation}

kde $f(x_1, x_2)$ je hodnota združenej hustoty pravdepodobnosti v bode $(x_1, x_2)$.

Presnejšie, pravdepodobnosť, že sa realizácie oboch premenných nachádzajú v oblasti $[a_1, b_1] \times [a_2, b_2]$, vypočítame pomocou dvojnásobného integrálu:

\begin{equation}
\mathrm{Pr}(a_1 \leq X_1 \leq b_1,\ a_2 \leq X_2 \leq b_2) = \int_{a_2}^{b_2} \int_{a_1}^{b_1} f(x_1, x_2) \, dx_1 \, dx_2
\end{equation}

Aby funkcia $f(x_1, x_2)$ bola platnou hustotou pravdepodobnosti, musí platiť:

\begin{equation}
\iint_{\mathbb{R}^2} f(x_1, x_2) \, dx_1 \, dx_2 = 1
\end{equation}

Združená hustota veľmi efektívne popisuje spoločné správanie dvoch spojitých náhodných premenných a tvorí základ pre ďalšie koncepty ako sú marginálne a podmienené rozdelenia.

Na nasledujúcom obrázku môžeme vidieť príklad vizualizácie združenej hustoty pravdepodobnosti homogénnej spojitej štruktúry dvoch premenných, pričom ako model výpočtu tu používame jadrové vyhladzovanie (kap.~\ref{textbf:kernel_smoothing}).

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.7\linewidth]{hustota_hlbka_dlzka_zobaku_3D}
    \caption{Združená hustota pravdepodobnosti (PDF) medzi premennými \textit{Hĺbka zobáku} a \textit{Dĺžka zobáku} tučniakov.}
    \label{fig:zobak_joint_density}
\end{figure}

\subsection{Momentové charakteristiky}\label{joint_moments}

Rovnako ako v jednorozmernom prípade, aj v prípade viacrozmerných náhodných veličín (náhodného vektora) sú základnými charakteristikami rozdelenia \textit{stredná hodnota} a \textit{rozptyl}, pričom tentokrát si zavedieme aj pojmy \textit{kovariancie} a \textit{korelačného koeficientu}.

\subsubsection{Stredná hodnota}\label{subsubsec:joint_mean}

Pre náš dvojrozmerný náhodný vektor \(\vec{X} = (X_1, X_2)\) definujeme vektor stredných hodnôt ako:

\begin{equation}
\mathbb{E}[\vec{X}] = \left( \mathbb{E}[X_1], \mathbb{E}[X_2] \right)
\end{equation}

Pre obidva komponenty ho môžeme vyjadriť pomocou marginálnej hustoty (kap.~\ref{subsec:marginal_dist}). Napríklad pre \(X_1\) a marginálnu hustotu \(f_1(x_1)\) platí:

\begin{equation}
\mathbb{E}[X_1] = \int_{\mathbb{R}} x_1 \, f_1(x_1) \, dx_1
\end{equation}

alebo pomocou združenej hustoty:

\begin{equation}
\mathbb{E}[X_1] = \iint_{\mathbb{R}^2} x_1 \, f(x_1, x_2) \, dx_1 \, dx_2
\end{equation}

\subsubsection{Rozptyl}\label{subsubsec:joint_variance}

Rozptyl (disperzia) je definovaný ako očakávaná kvadratická odchýlka od strednej hodnoty:

\begin{equation}
\mathrm{Var}[X_1] = \mathbb{E}[(X_1 - \mathbb{E}[X_1])^2]
\end{equation}

Alternatívne možno rozptyl zapísať aj ako rozdiel momentov:

\begin{equation}
\mathrm{Var}[X_1] = \mathbb{E}[X_1^2] - (\mathbb{E}[X_1])^2
\end{equation}

\subsubsection{Kovariancia}\label{subsubsec:joint_covariance}

Kovariancia vyjadruje mieru lineárnej závislosti medzi dvoma náhodnými premennými \(X_1\) a \(X_2\). Definujeme ju ako:

\begin{equation}
\mathrm{Cov}[X_1, X_2] = \mathbb{E}[(X_1 - \mathbb{E}[X_1])(X_2 - \mathbb{E}[X_2])]
\end{equation}

Kovariancia sa dá alternatívne vyjadriť aj pomocou spoločného momentu:

\begin{equation}
\mathrm{Cov}[X_1, X_2] = \mathbb{E}[X_1 X_2] - \mathbb{E}[X_1] \cdot \mathbb{E}[X_2]
\end{equation}

Tieto hodnoty sa sumarizujú do dvojdimenzionálnej \textit{kovariančnej matice} \(\Sigma\), ktorá je symetrická a pozitívne semidefinitná:

\begin{equation}
\Sigma = 
\begin{bmatrix}
\mathrm{Var}[X_1] & \mathrm{Cov}[X_1, X_2] \\
\mathrm{Cov}[X_2, X_1] & \mathrm{Var}[X_2] \\
\end{bmatrix}
\end{equation}

Kovariančná matica je nevyhnutným nástrojom pre analýzu rozptylu a závislostí medzi komponentami náhodného vektora. Využíva sa napríklad pri odhade parametrov v lineárnej regresii alebo v diskriminačnej analýze.

\subsubsection{Korelačný koeficient}\label{subsubsec:correlation}

Aj keď kovariancia $\mathrm{Cov}[X_1, X_2]$ vyjadruje spoločnú variabilitu dvoch náhodných premenných $X_1$ a $X_2$, jej interpretácia môže byť problematická, pretože jej hodnota závisí od mierky jednotlivých premenných. Teda rovnaká úroveň závislosti medzi premennými môže viesť k rôznym hodnotám kovariancie, ak sú tieto premenné škálované rozdielne.

Túto nevýhodu rieši tzv. \textit{Pearsonov korelačný koeficient}, ktorý je definovaný ako normalizovaná kovariancia:

\begin{equation}
\rho(X_1, X_2) = \frac{\mathrm{Cov}[X_1, X_2]}{\sqrt{\mathrm{Var}[X_1] \cdot \mathrm{Var}[X_2]}}
\end{equation}

Hodnota $\rho(X_1, X_2)$ leží vždy v intervale $[-1, 1]$, pričom:

\begin{itemize}
  \item $\rho = 1$ znamená úplnú pozitívnu lineárnu závislosť,
  \item $\rho = -1$ znamená úplnú negatívnu lineárnu závislosť,
  \item $\rho = 0$ znamená žiadnu lineárnu závislosť (lineárna nezávislosť).
\end{itemize}

Dôležité je, že korelačný koeficient (rovnako ako kovariancia) meria iba \textit{lineárnu} závislosť medzi premennými. Nulová korelácia teda neznamená, že premenné sú nezávislé – iba že medzi nimi nie je lineárny vzťah. Naopak, ak sú dve premenné nezávislé, ich kovariancia aj korelácia sú vždy nulové.

\subsection{Marginálne rozdelenie}\label{subsec:marginal_dist}

Ak nás nezaujíma spoločné správanie všetkých náhodných premenných vektorovej premennej $\vec{X} = (X_1, X_2)$, ale iba jedného jej komponentu, môžeme skúmať jej vlastné pravdepodobnostné rozdelenie. Takéto rozdelenie nazývame \textit{marginálne rozdelenie} (angl. marginal distribution).

Na vizualizáciu marginálneho rozdelenia danej premennej, napríklad $X_2$, môžeme premietnuť každý bod z roviny $(x_1, x_2)$ na os $x_2$ a zostrojiť tak histogram týchto projekcií. Výsledný histogram, po normalizácii tak, aby plocha všetkých stĺpcov bola rovná 1, poskytuje empirický odhad marginálneho rozdelenia $X_2$.

\begin{figure}[H] 
    \centering 
    \includegraphics[width=0.7\linewidth]{marg_proj_hist.png} 
    \caption{Empirický odhad marginálneho rozdelenia premennej $X_2$} 
    \label{fig:margin_proj} 
\end{figure}

Z iného pohľadu, marginálne rozdelenie premennej $X_2$ vyjadruje pravdepodobnosť, že hodnota $X_2$ spadne do veľmi úzkeho intervalu $[x_2, x_2 + dx_2]$. V kontexte dvojrozmerného bodového grafu to zodpovedá pravdepodobnosti, že sa bod $(x_1, x_2)$ nachádza v horizontálnom páse výšky $dx_2$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{marg_strip_sum1.png}
        \caption{Horizontálny pás šírky $dx_2$ reprezentujúci interval pre $X_2$.}
        \label{fig:marg_strip_a}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{marg_strip_sum2.png}
        \caption{Pás rozdelený na plôšky $dx_1 \cdot dx_2$, z ktorých sa skladá marginálne rozdelenie $X_2$.}
        \label{fig:marg_strip_b}
    \end{subfigure}
    \caption{Vizuálna interpretácia marginálneho rozdelenia premennej $X_2$}
    \label{fig:marg_strip}
\end{figure}

Ak si pás rozdelíme na plôšky $dx_1 \cdot dx_2$  (Obr.~\ref{fig:marg_strip_b}), potom z nich váženým súčtom dostaneme:

\begin{equation}
\mathrm{Pr}(x_2 \leq X_2 \leq x_2 + dx_2) \approx \sum_i f(x_1^{(i)}, x_2) \, dx_1 \, dx_2
\end{equation}

Porovnaním so vzťahom pre jednorozmernú hustotu pre spojité premenné nám vychádza vzťah, ktorý hovorí o tom, že marginálne rozdelenie $X_2$ možno získať z hustoty združeného rozdelenia $f(x_1, x_2)$ integráciou cez všetky hodnoty $x_1$:

\begin{equation} f_2(x_2) = \int_{-\infty}^{\infty} f(x_1, x_2) dx_1 \end{equation}

Podobne marginálne rozdelenie premennej $X_1$ získame ako:

\begin{equation} f_1(x_1) = \int_{-\infty}^{\infty} f(x_1, x_2)  dx_2 \end{equation}

Tieto marginálne rozdelenia slúžia ako základ pre rozklad združeného rozdelenia pomocou kopúl, ktorému sa budeme venovať v samostatnej podkapitole.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{hustota_hlbka_dlzka_zobaku_2D}
    \caption{Vrstevnice združenej PDF(Obr.~\ref{fig:zobak_joint_density}) + po bokoch marginálne PDF premenných \textit{Hĺbka zobáku} a \textit{Dĺžka zobáku} tučniakov (metóda: jadrové vyhladzovanie ~\ref{textbf:kernel_smoothing})}
    \label{fig:zobak_marg_density}
\end{figure}

\subsection{Podmienené rozdelenie}\label{subsec:conditional_distribution}

Kým marginálne rozdelenie opisuje správanie jednej premennej bez toho aby sa bral do úvahy vplyv ostatných premenných na túto premennú, v mnohých praktických situáciách nás zaujíma, ako sa rozdelenie jednej premennej mení v závislosti od známych hodnôt inej premennej. V takýchto prípadoch hovoríme o \textit{podmienenom rozdelení}.

\subsubsection{Hustota}\label{subsubsec:conditional_density}

Formálne, ak máme náhodný vektor $(X_1, X_2)$, potom podmienená hustota premennej $X_2$ vzhľadom na známu hodnotu $X_1 = x_1$ je definovaná ako:

\begin{equation}
f_{2 \mid 1}(x_2 \mid x_1) = \frac{f(x_1, x_2)}{f_1(x_1)},
\end{equation}

kde:
\begin{itemize}
  \item $f(x_1, x_2)$ je združená hustota,
  \item $f_1(x_1) = \int_{-\infty}^{\infty} f(x_1, x_2) \, dx_2$ je marginálna hustota premennej $X_1$.
\end{itemize}

Z definície o podmienenej pravdepodobnosti vyplýva:

\begin{equation}
\mathrm{Pr}(a \leq X_2 \leq b \mid X_1 = x_1) = \int_a^b f_{2 \mid 1}(x_2 \mid x_1) \, dx_2.
\end{equation}

Podmienenú hustotu $f_{2 \mid 1}(x_2 \mid x_1)$ tu taktiež možno intuitívne interpretovať ako hustotu v rámci tenkého vertikálneho pásu, kde náhodná premenná $X_1$ nadobúda hodnoty z intervalu $[x, x + \varepsilon]$ (Obr.~\ref{fig:cond_density_strip}). V tomto pásme vyberieme všetky body, ktoré spadajú do daného intervalu a z nich vytvoríme histogram hodnôt premennej $X_2$, čím získame empirický odhad hustoty $f_{2 \mid 1}(x_2 \mid x \leq X_1 \leq x +\epsilon)$.

Pre lepšiu predstavu je tento postup znázornený na nasledujúcom obrázku:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{marg_condition_strip.png}
    \caption{Empirický odhad podmienenej hustoty $f_{2 \mid 1}(x_2 \mid x_1 \in [x, x + \epsilon])$}
    \label{fig:cond_density_strip}
\end{figure}

Týmto sme zaviedli pojem podmienenej hustoty, ktorý bude ďalej kľúčový pri výpočte tzv. \textit{podmienenej strednej hodnoty}. Na ďalšom obrázku môžeme vidieť príklad vizualizácie podmienených hustôt pre spojitú odozvu a prediktor.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{cond_normal_densities.png}
    \caption{Podmienené hustoty pre premenné (Odozva) $Y=$ \textit{Dĺžka zobáka tučniaka} a (Prediktor) $X=$ \textit{Hmotnosť tučniaka v gramoch} (parametrický prístup: \textit{normálne rozdelenie}, kap.~\ref{subsubsec:parametric_models})}
    \label{fig:cond_normal_densities}
\end{figure}

\subsubsection{Stredná hodnota}\label{subsubsec:conditional_mean}

Vo všeobecnosti podmienená stredná hodnota vyjadruje očakávanú hodnotu jednej náhodnej premennej vzhľadom na známu hodnotu inej premennej.

Pre diskrétne náhodné premenné $X$ a $Y$ je podmienená stredná hodnota premennej $Y$ vzhľadom na to, že $X = x$, definovaná ako:

\begin{equation}
\mu_{Y|X} = \mathbb{E}[Y|X = x] = \sum_{y} y \cdot \mathrm{Pr}(Y = y \mid X = x)
\end{equation}

Analogicky, ak ide o spojité premenné, tak platí:

\begin{equation}
\mu_{Y|X} = \mathbb{E}[Y|X = x] = \int_{-\infty}^{\infty} y \cdot f_{Y|X}(y \mid x) \, dy
\end{equation}

kde $f_{Y|X}(y \mid x)$, ako už vieme z predošlej podkapitoly, je v tomto prípade podmienená hustota pravdepodobnosti náhodnej premennej $Y$ za predpokladu, že $X = x$.

Podmienená stredná hodnota je teda funkciou známej hodnoty inej premennej a v kontexte regresného modelovania častokrát vystupuje ako regresná funkcia. Napríklad, funkcia $\mu_{Y|X}$ opisuje očakávaný výstup $Y$ vzhľadom na vstup $x$, čo presne zodpovedá určeniu deterministickej zložky regresného modelu.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{podm_stredna_hodnota.png}
    \caption{Podmienená stredná hodnota pre premenné (Odozva) $Y=$ \textit{Dĺžka zobáka tučniaka} a (Prediktor) $X=$ \textit{Hmotnosť tučniaka v gramoch} s vypočítanou hodnotou v $\mathbb{E}[Y \mid X=5000]$}
    \label{fig:cond_mean}
\end{figure}

\subsubsection{Kvantilová funkcia}
\label{subsubsec:conditional_quantile_function}

Kvantilová regresia (\textit{Quantile Regression}, QR) umožňuje odhadovať \textit{kvantily podmieneného rozdelenia} odozvy vzhľadom na hodnoty prediktora. Na rozdiel od klasickej regresie, ktorá sa zameriava iba na strednú hodnotu $\mathbb{E}[Y \mid X = x]$, kvantilová regresia modeluje \textit{celú podmienenú distribúciu}.

Pre daný kvantil $q \in (0,1)$ je \textit{podmienená kvantilová funkcia} definovaná ako:
\begin{equation}
Q_{Y \mid X}(q) := \inf \left\{ y \in \mathbb{R} \mid \Pr(Y \leq y \mid X = x) \geq q \right\}
\end{equation}

V prípade \textit{lineárnej kvantilovej regresie} sa predpokladá, že kvantilová funkcia má tvar:

\begin{equation}
Q_{Y \mid X}(q) = X^\top \beta_q
\end{equation}

kde $\beta_q$ je vektor parametrov pre daný kvantil $q$. Tento prístup umožňuje skúmať účinok kovariátov nielen na strednú hodnotu, ale aj na ľubovoľný kvantil podmieneného rozdelenia.

Parametre $\beta_q$ sa odhadujú pomocou minimalizácie cieľovej funkcie:

\begin{equation}
\hat{\beta}_q = \arg\min_{\beta \in \mathbb{R}^p} \sum_{i=1}^n \rho_q (y_i - x_i^\top \beta)
\end{equation}
kde $\rho_q(u)$ je definovaná ako:
\begin{equation}
\rho_q(u) = u(q - \mathbb{I}(u < 0))
\end{equation}

\textbf{Výhody kvantilovej regresie:}
\begin{itemize}
  \item Zachytáva \textit{heteroskedasticitu}, teda zmenu variability odozvy vzhľadom na hodnoty kovariátov.
  \item Poskytuje detailnejší obraz o štruktúre dát — napríklad rôzne účinky kovariátov v nízkych a vysokých kvantiloch.
  \item Je robustná voči odľahlým hodnotám.
\end{itemize}

Na nasledujúcom obrázku môžeme pozorovať kvantilové funkcie pre vybrané kvantily vo vzťahu k strednej hodnote.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{cond_quant_func.png}
    \caption{Podmienené kvantilové funkcie $Q_{Y \mid X}(0.05)$, $Q_{Y \mid X}(0.95)$ a stredná hodnota $\mathbb{E}[Y \mid X]$ pre premenné $Y=$ \textit{Dĺžka zobáka tučniaka} a $X=$ \textit{Hmotnosť tučniaka v gramoch} s vypočítanou hodnotou v $X=5000$}
    \label{fig:cond_quant_mean}
\end{figure}

\section{Rozklad}\label{sec:rozklad_kopule}

Modelovanie viacrozmerného náhodného vektora nie je vždy efektívne, ak sa snažíme zachytiť spoločné správanie jeho zložiek prostredníctvom jednej združenej distribučnej funkcie (CDF). Tento prístup totiž neumožňuje samostatne modelovať štruktúru závislosti a vlastností jednotlivých premenných.

Vhodnou alternatívou tu je preto rozklad združeného rozdelenia pravdepodobnosti na dve zložky:
\begin{itemize}
  \item \textit{marginálne rozdelenia} jednotlivých komponentov náhodného vektora,
  \item \textit{kopulu} – funkciu, ktorá tieto marginály spája do jedného celku a zachytáva ich vzájomnú závislosť.
\end{itemize}

Tento prístup formuluje tzv. \textit{Sklarova veta}, ktorá v dvojrozmernom prípade pre každú spojitú distribučnú funkciu $F(x_1, x_2)$ zabezpečuje existenciu unikátnej kopuly $C$, pre ktorú platí:

\begin{equation}\label{eq:copula_dist}
F(x_1, x_2) = C\left(F_1(x_1), F_2(x_2)\right)
\end{equation}

Pre funkciu hustoty dostávame nasledovný rozklad:

\begin{equation}\label{eq:copula_density}
f(x_1, x_2) = c\left(F_1(x_1), F_2(x_2)\right) \cdot f_1(x_1) \cdot f_2(x_2)
\end{equation}

kde $f_1(x_1)$ a $f_2(x_2)$ sú \textit{marginálne hustoty} a $c(u_1, u_2)$ je hustota kopuly.

Tento rozklad nám umožňuje samostatne modelovať:
\begin{itemize}
  \item \textit{tvar individuálnych rozdelení} (napr. normálne, log-normálne, gama, atď.),
  \item \textit{závislosť medzi premennými} prostredníctvom voľby vhodnej kopuly (napr. Gaussova, t-kopula, Claytonova, Gumbelova, atď.).
\end{itemize}

Pre zjednodušenie sa častokrát používajú transformácie do tzv. \textit{uniformného priestoru}, pričom každá náhodná premenná $X_i$ sa nahradí svojou distribučnou funkciou $U_i = F_i(X_i)$, čím vznikne nový vektor $(U_1, U_2)$, ktorého všetky komponenty sú rovnomerne rozdelené na intervale $[0,1]$.

Tento princíp je ilustrovaný na nasledujúcom obrázku:

\begin{figure}[H]
    \centering
    \begin{minipage}{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{dist_transform_pred.png}
    \end{minipage}
    \begin{minipage}{0.05\linewidth}
        \centering
        \Huge$\Rightarrow$
    \end{minipage}
    \begin{minipage}{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{SK_verzia_praca/figures/dist_transform_po.png}
    \end{minipage}
    \caption{Rozklad združeného rozdelenia: pôvodné hodnoty $(x, y)$ s rôznymi marginálami (vľavo) sú transformované cez $F_1$, $F_2$ na $(u,v)$ (vpravo), ktoré majú rovnomerné rozdelenie na $[0,1]$. Spoločná závislosť sa prenáša do tvaru kopuly.}
    \label{fig:sklar_transform}
\end{figure}

Výhoda tohto prístupu spočíva v tom, že umožňuje flexibilne kombinovať rôzne marginálne rozdelenia s rôznymi typmi závislostí a výrazne zjednodušuje modelovanie a výpočet podmienených rozdelení, čo je užitočné pri predikcii, rôznych simuláciách a v aplikáciách akou je napríklad kvantilová regresia.

\subsection{Kopule}
\label{subsec:copulas}

Kopula je matematická funkcia, ktorá umožňuje oddeliť modelovanie marginálnych rozdelení od modelovania závislosti medzi náhodnými premennými (pozri~\ref{eq:copula_dist} a ~\ref{eq:copula_density}).

\subsubsection{Vlastnosti}

Každá kopula $C: [0,1]^p \to [0,1]$ musí spĺňať nasledovné vlastnosti:

\begin{itemize}
  \item Hraničné podmienky: $C(u_1, \dots, u_i = 0, \dots, u_p) = 0$ pre ľubovoľné $i$.
  \item Identita: $C(1, \dots, 1, u_i, 1, \dots, 1) = u_i$.
  \item $p$-rastúca: pre $p=2$ platí:
  \begin{equation}
    C(v_1, v_2) - C(v_1, u_2) - C(u_1, v_2) + C(u_1, u_2) \geq 0, \quad \text{ak } u_i \leq v_i.
  \end{equation}
\end{itemize}

\subsubsection{Špeciálne prípady}

\begin{itemize}
  \item \textit{Kopula nezávislosti} (produktová):
  \begin{equation}
  \Pi(u_1, \dots, u_p) = u_1 \cdot \dots \cdot u_p.
  \end{equation}
  \item \textit{Kopula úplnej závislosti}:
  \begin{equation}
  M(u_1, \dots, u_p) = \min(u_1, \dots, u_p).
  \end{equation}
  \item \textit{Kopula úplnej negatívnej závislosti (iba pre $p=2$)}:
  \begin{equation}
  W(u_1, u_2) = \max(0, u_1 + u_2 - 1).
  \end{equation}
\end{itemize}

Pre dvojrozmerný prípad platí ohraničenie kopuly:
\[
W(u_1, u_2) \leq C(u_1, u_2) \leq M(u_1, u_2).
\]

\subsubsection{Využitie modelu závislosti}

Kopula predstavuje štruktúru závislosti v združenom modeli. Umožňuje napríklad výpočet:

\begin{itemize}
  \item Spoločnej pravdepodobnosti: $\Pr(U_1 \leq u_1,\, U_2 \leq u_2) = C(u_1, u_2)$,
  \item Pravdepodobnosti prekročenia: $\Pr(U_1 > u_1 \vee U_2 > u_2) = 1 - C(u_1, u_2)$,
  \item Podmienených pravdepodobností:
  \[
  \Pr(U_1 \leq u_1 \mid U_2 = u_2) = \frac{\partial C(u_1, u_2)}{\partial u_2}.
  \]
\end{itemize}

\subsubsection{Parametrické triedy}\label{subsubsec:parametric_copula}

\begin{itemize}
  \item \textit{Eliptické kopuly} – napr. Gaussova, t-kopula: modelujú lineárnu závislosť a sú konštruované cez štandardizáciu marginálií eliptických rozdelení:
  
  \begin{equation}
    C_{\Phi}(u_1, \dots, u_p) = \Phi\left( \Phi_1^{-1}(u_1), \dots, \Phi_p^{-1}(u_p) \right)
  \end{equation}

  \item \textit{Archimedovské kopuly} – napr. Gumbelova, Claytonova, Frankova: jednoduché konštrukcie pomocou generátora $f:[0,1] \to [0,\infty)$:

  \begin{equation}
  C(u_1, \dots, u_p) = f^{-1}\left( f(u_1) + \dots + f(u_p) \right)
  \end{equation}

  \item \textit{Extreme-value kopuly} – napr. Gumbelova: vhodné pre modelovanie maximálnych javov (napr. povodne). Generované pomocou \textit{dependence function} $\ell : [0, \infty)^p \rightarrow [0, \infty)$:

  \begin{equation}
  C(u_1, \dots, u_p) = \exp\left(-\ell(-\log u_1, \dots, -\log u_p)\right)
  \end{equation}
  
\end{itemize}

Pre porovnanie jednotlivých typov kopúl sme si spravili nasledujúce simulácie.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{parametric_copulas.png}
    \caption{Simulácie náhodných výberov}
    \label{fig:parametric_copulas}
\end{figure}

\subsubsection{Neparametrické triedy}\label{subsubsec:nonparametric_copula}

\textit{Empirická kopula} je neparametrický odhad kopuly vytvorený priamo z dát bez predpokladu konkrétneho modelu (žiadna Gumbel, Clayton ani t-distribúcia).

Je definovaná ako:

\begin{equation}
C_n(u, v) = \frac{1}{n} \sum_{i=1}^{n} \mathbf{1}\left( \hat{U}^{(i)} \leq u,\ \hat{V}^{(i)} \leq v \right)
\end{equation}

kde $\left(\hat{U}^{(i)}, \hat{V}^{(i)}\right)$ sú \textit{pseudo-observácie}, teda transformované dáta pomocou empirických distribučných funkcií (ECDF) na interval $[0,1]$.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{nonparametric_copula.png}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{nonparametric_copula_dens.png}
    \end{minipage}
    \caption{Empirická kopula: Simulácia náhodného výberu + hustota pravdepodobnosti (marginálie: jadrové vyhladzovanie, ~\ref{textbf:kernel_smoothing})}
    \label{fig:empcopula}
\end{figure}

\section{Odhad}\label{sec:odhad}

V predchádzajúcich častiach sme sa venovali teoretickému rámcu združených rozdelení pravdepodobnosti a ich dekompozícii pomocou marginálnych rozdelení a kopúl. V tejto časti sa zameriame na praktický aspekt — teda ako možno parametre týchto modelov odhadnúť zo vzorky dát, pričom sa opäť obmedzíme na dvojrozmerné prípady. Predpokladáme, že rozdelenie náhodného vektora $\vec{X} = (X_1, X_2)$ patrí do známej parametrickej triedy rozdelení s parametrami $\theta \in \Theta$.

Na tento účel sa najčastejšie používajú tri základné prístupy:

\subsection{Metóda momentov}\label{subsection:moments_method}

Metóda momentov vychádza z priameho vzťahu medzi teoretickými momentami rozdelenia a jeho parametrami. Tieto momenty sa nahradia empirickými momentami (z výberu) a výsledný súbor rovníc sa vyrieši vzhľadom na neznáme parametre.

Táto metóda má výhodu v jednoduchej implementácii a nízkych výpočtových nárokoch. Na druhej strane, nie vždy existuje jednoznačný alebo analytický vzťah medzi momentami a parametrami, čo obmedzuje jej použiteľnosť. Navyše, výsledné odhady nemajú vo všeobecnosti optimálne vlastnosti ako napríklad minimálnu varianciu.

\subsection{Metóda maximálnej vierohodnosti (Maximum Likelihood, ML)}\label{subsection:max_likelihood}

Tento prístup odhaduje parametre $\theta$ maximalizáciou logaritmickej vierohodnostnej funkcie, ktorá vyjadruje pravdepodobnosť výskytu pozorovanej vzorky vzhľadom na daný model. Formálne:

\begin{equation}
\hat{\theta} = \arg\max_{\theta \in \Theta} \frac{1}{n} \sum_{i=1}^{n} \ln f(X_{i1}, X_{i2} \mid \theta)
\end{equation}

Metóda maximálnej vierohodnosti vedie k odhadom, ktoré sú:
\begin{itemize}
  \item \textit{konzistentné} – konvergujú v pravdepodobnosti ku skutočnej hodnote parametra pre $n \to \infty$,
  \item \textit{nevychýlené (angl. unbiased)} – v priemere odhadujú pravú hodnotu,
  \item \textit{efektívne} – majú najmenší možný rozptyl,
  \item \textit{asymptoticky normálne rozdelené}.
\end{itemize}

Nevýhodou tejto metódy je jej vyššia výpočtová náročnosť, závislosť od počiatočných hodnôt a možná vychýlenosť pri malých výberoch.

\subsection{Metóda najmenších štvorcov}\label{subsec:least_squares}

Táto metóda vychádza z minimalizácie vzdialenosti medzi teoretickou distribučnou funkciou modelu a jej empirickým odhadom. Napríklad vo forme:

\begin{equation}
\hat{\theta} = \arg\min_{\theta \in \Theta} \sum_{i=1}^{n} \left( F(X_{i1}, X_{i2} \mid \theta) - \hat{F}_n(X_{i1}, X_{i2}) \right)^2
\end{equation}

Metóda najmenších štvorcov je univerzálnejšia a často sa používa tam, kde nie je možné jednoducho odvodiť vierohodnostnú funkciu. Napriek tomu však nemusí poskytovať také dobré vlastnosti odhadov ako ML.

\vspace{1em}

Každý z vyššie uvedených prístupov má svoje opodstatnenie a vhodnosť ich použitia závisí od typu rozdelenia, počtu pozorovaní a účelu analýzy.
